{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2fa8319",
   "metadata": {},
   "source": [
    "# Program Topic Modelling menggunakan LSA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3b67f",
   "metadata": {},
   "source": [
    "Latent Dirichlet Allocation (LDA) adalah model probabilistik generatif dari koleksi data diskrit seperti korpus teks. Ide dasarnya adalah bahwa dokumen direpresentasikan sebagai campuran acak atas topik laten (tidak terlihat).\n",
    "\n",
    "LDA merupakan model Bayesian hirarki tiga tingkat, di mana setiap item koleksi dimodelkan sebagai campuran terbatas atas serangkaian set topik. Setiap topik dimodelkan sebagai campuran tak terbatas melalui set yang mendasari probabilitas topik. Dalam konteks pembuatan model teks, probabilitas topik memberikan representasi eksplisit dari sebuah dokumen.\n",
    "\n",
    "Algoritma LSA (Latent Semantic Analysis) adalah salah satu algoritma yang dapat digunakan untuk menganalisa hubungan antara sebuah frase/kalimat dengan sekumpulan dokumen. Contoh yang dibahas kali ini adalah mengenai penentuan urutan peringkat data berdasarkan query yang digunakan. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c3818",
   "metadata": {},
   "source": [
    "## Install Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaab957",
   "metadata": {},
   "source": [
    "<p>Beberapa Hal yang pertama kali harus di persiapkan adalah libray-library yang akan dipakai. kita perlu menginstall library nltk yaitu sebuah library yang digunakan untuk membantu kita dalam bekerja dengan teks. Kemudian library pandas yaitu library yang mengatur tata letak data sehingga mudah dicari secara intuitif. selanjutnya library numpy untuk melakukan operasi vektor dan matriks dengan mengolah array dan array multidimensi. Dan library scikit-learn untuk membangun model pembelajaran mesin. Ia menyediakan banyak algoritma pembelajaran untuk regresi, pengelompokan, dan klasifikasi.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f812c348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.23.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sklearn) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.23.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.23.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.8.1)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.23.0)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2022.6.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52610e",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b84d5a",
   "metadata": {},
   "source": [
    "<p>Untuk library yang digunakan diantaranya ada numpy, pandas, matplotlib, seaborn, nltk, dan sklearn, library ini umum digunakan pada data processing</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724deafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "#preprocessing\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "\n",
    "# for named entity recognition (NER)\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# vectorizers for creating the document-term-matrix (DTM)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "\n",
    "#stop-words\n",
    "stop_words=set(nltk.corpus.stopwords.words('indonesian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17637b3e",
   "metadata": {},
   "source": [
    "<h3>Instalasi Library Tambahan</h3>\n",
    "<p>Di bawah ini ada library tambahan yang harus di-install untuk memproses kata-kata yang diolah, terdapat corpus, stopwprds, punkt</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82611360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading corpus: Package 'corpus' not found in index\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('corpus')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ffe3ef",
   "metadata": {},
   "source": [
    "## Import dokumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8221245",
   "metadata": {},
   "source": [
    "<p>Import dokumen yang sudah dicrawling dengan crawler sebelumnya. Disini saya memasukkan data berformat csv. Nama filenya adalah jurnal.csv</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77d3fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'jurnal.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60bce0",
   "metadata": {},
   "source": [
    "### Tampilan dari 10 data yang diproses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b485343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judul</th>\n",
       "      <th>Abstrak_indo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANALISIS PORTOFOLIO YANG OPTIMAL DI BEI DENGAN...</td>\n",
       "      <td>Suatu keputusan investasi selalu berhubungan d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pengaruh Bauran Pemasaran Terhadap Keputusan P...</td>\n",
       "      <td>Objek penelitian ini adalah pembelian produk X...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analisis faktor-faktor yang berpengaruh terhad...</td>\n",
       "      <td>ABSTRAK\\r\\nTujuan penelitian ini adalah untuk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analisis Inovasi Dan Keunggulan Bersaing \\r\\nD...</td>\n",
       "      <td>ABSTRAK\\r\\n\\tTujuan penelitian ini adalah mend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PENGARUH FAKTOR-FAKTOR PELATIHAN DAN PENGEMBAN...</td>\n",
       "      <td>ABSTRAK\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PENGARUH HARGA DAN KUALITAS PRODUK TERHADAP KE...</td>\n",
       "      <td>ABSTRAK \\r\\nTujuan penelitian ini adalah (1) U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PENGARUH KOMPETENSI DOSEN TERHADAP KINERJA DOS...</td>\n",
       "      <td>Abstrak\\r\\n\\r\\nAththaariq, Pengaruh Kompetensi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PENGARUH KUALITAS PELAYANAN TERHADAP KEPUASAN ...</td>\n",
       "      <td>ABSTRAK\\r\\n\\r\\nTujuan penelitian ini adalah un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PENGARUH STRUKTUR MODAL DAN LIKUIDITAS TERHADA...</td>\n",
       "      <td>Pendekatan penelitian yang digunakan dalam pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pengaruh Kompensasi Terhadap Kinerja Karywan p...</td>\n",
       "      <td>ABSTRAK \\r\\n\\r\\n\\tTujuan penelitian ini adalah...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Judul  \\\n",
       "0  ANALISIS PORTOFOLIO YANG OPTIMAL DI BEI DENGAN...   \n",
       "1  Pengaruh Bauran Pemasaran Terhadap Keputusan P...   \n",
       "2  analisis faktor-faktor yang berpengaruh terhad...   \n",
       "3  Analisis Inovasi Dan Keunggulan Bersaing \\r\\nD...   \n",
       "4  PENGARUH FAKTOR-FAKTOR PELATIHAN DAN PENGEMBAN...   \n",
       "5  PENGARUH HARGA DAN KUALITAS PRODUK TERHADAP KE...   \n",
       "6  PENGARUH KOMPETENSI DOSEN TERHADAP KINERJA DOS...   \n",
       "7  PENGARUH KUALITAS PELAYANAN TERHADAP KEPUASAN ...   \n",
       "8  PENGARUH STRUKTUR MODAL DAN LIKUIDITAS TERHADA...   \n",
       "9  Pengaruh Kompensasi Terhadap Kinerja Karywan p...   \n",
       "\n",
       "                                        Abstrak_indo  \n",
       "0  Suatu keputusan investasi selalu berhubungan d...  \n",
       "1  Objek penelitian ini adalah pembelian produk X...  \n",
       "2  ABSTRAK\\r\\nTujuan penelitian ini adalah untuk ...  \n",
       "3  ABSTRAK\\r\\n\\tTujuan penelitian ini adalah mend...  \n",
       "4                                      ABSTRAK\\r\\...  \n",
       "5  ABSTRAK \\r\\nTujuan penelitian ini adalah (1) U...  \n",
       "6  Abstrak\\r\\n\\r\\nAththaariq, Pengaruh Kompetensi...  \n",
       "7  ABSTRAK\\r\\n\\r\\nTujuan penelitian ini adalah un...  \n",
       "8  Pendekatan penelitian yang digunakan dalam pen...  \n",
       "9  ABSTRAK \\r\\n\\r\\n\\tTujuan penelitian ini adalah...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a1e275",
   "metadata": {},
   "source": [
    "## Teks Prosesing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b265cb",
   "metadata": {},
   "source": [
    "<p>Pembersihan dokumen diperlukan agar dalam proses TF/IDF tidak ada simbol-simbol yang ikut masuk ke dalam proses tersebut yang dapat mengakibatkan dokumen menjadi kurang otentik</p><br>\n",
    "\n",
    "<p>Pada tahap ini terdapat tahap tokenizing (memotong kata pada white space atau spasi dan membuang karakter tanda baca) dan tahap stopword (kata-kata umum (Commond words) yang sering muncul, yang tidak memberikan informasi penting (yang biasanya tidak diacuhkan atau dibuang misalnya dalam proses pembuatan indeks atau daftar kata). Contoh stopword bahasa Indonesia antara lain “yang”,”di”,”ke”,dll)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa3dae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(headline):\n",
    "    le=WordNetLemmatizer()\n",
    "    word_tokens=word_tokenize(headline)\n",
    "    tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
    "    cleaned_text=\" \".join(tokens)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12deb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time taking\n",
    "df['abstrak_cleaned']=df['Abstrak_indo'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861396e",
   "metadata": {},
   "source": [
    "### Perbandingan data yang belum dan sudah dibersihkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b15dd74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judul</th>\n",
       "      <th>Abstrak_indo</th>\n",
       "      <th>abstrak_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANALISIS PORTOFOLIO YANG OPTIMAL DI BEI DENGAN...</td>\n",
       "      <td>Suatu keputusan investasi selalu berhubungan d...</td>\n",
       "      <td>Suatu keputusan investasi berhubungan keuntung...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pengaruh Bauran Pemasaran Terhadap Keputusan P...</td>\n",
       "      <td>Objek penelitian ini adalah pembelian produk X...</td>\n",
       "      <td>Objek penelitian pembelian produk Kecamatan Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analisis faktor-faktor yang berpengaruh terhad...</td>\n",
       "      <td>ABSTRAK\\r\\nTujuan penelitian ini adalah untuk ...</td>\n",
       "      <td>ABSTRAK Tujuan penelitian pengaruh variabel cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analisis Inovasi Dan Keunggulan Bersaing \\r\\nD...</td>\n",
       "      <td>ABSTRAK\\r\\n\\tTujuan penelitian ini adalah mend...</td>\n",
       "      <td>ABSTRAK Tujuan penelitian mendeskripsikan inov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PENGARUH FAKTOR-FAKTOR PELATIHAN DAN PENGEMBAN...</td>\n",
       "      <td>ABSTRAK\\r\\...</td>\n",
       "      <td>ABSTRAK Satiyah Pengaruh Faktor-faktor Pelatih...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Judul  \\\n",
       "0  ANALISIS PORTOFOLIO YANG OPTIMAL DI BEI DENGAN...   \n",
       "1  Pengaruh Bauran Pemasaran Terhadap Keputusan P...   \n",
       "2  analisis faktor-faktor yang berpengaruh terhad...   \n",
       "3  Analisis Inovasi Dan Keunggulan Bersaing \\r\\nD...   \n",
       "4  PENGARUH FAKTOR-FAKTOR PELATIHAN DAN PENGEMBAN...   \n",
       "\n",
       "                                        Abstrak_indo  \\\n",
       "0  Suatu keputusan investasi selalu berhubungan d...   \n",
       "1  Objek penelitian ini adalah pembelian produk X...   \n",
       "2  ABSTRAK\\r\\nTujuan penelitian ini adalah untuk ...   \n",
       "3  ABSTRAK\\r\\n\\tTujuan penelitian ini adalah mend...   \n",
       "4                                      ABSTRAK\\r\\...   \n",
       "\n",
       "                                     abstrak_cleaned  \n",
       "0  Suatu keputusan investasi berhubungan keuntung...  \n",
       "1  Objek penelitian pembelian produk Kecamatan Ba...  \n",
       "2  ABSTRAK Tujuan penelitian pengaruh variabel cu...  \n",
       "3  ABSTRAK Tujuan penelitian mendeskripsikan inov...  \n",
       "4  ABSTRAK Satiyah Pengaruh Faktor-faktor Pelatih...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e8f7c",
   "metadata": {},
   "source": [
    "<p>Data frame kolom abstrak_cleaned</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98266d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Suatu keputusan investasi berhubungan keuntungan risiko Investor rasional menginvestasikan dananya saham efisien saham return risiko minimal Sampel penelitian saham aktif berdasarkan frekuensi perdagangan membagi dividen Tujuan penelitian membentuk portofolio optimal perbedaan return risiko saham kandidat kandidat portofolio Hasil penelitian saham kandidat portofolio saham diteliti nilai cut-off-point 0.76692 Portofolio optimal dibentuk saham excess return beta diperoleh saham masuk perhitungan portofolio optimal Komposisi proporsi dana saham Adaro Energy 12.597 Gudang Garam 13.417 Sampoerna 12.418 Astra Otopart 2.679 Multi Bintang Indonesia 8.225 Astra Agro Lestari 6.846 Goodyear Indonesia 2.973 Indika Energy 5.377 United Tractors 13.88 Pabrik Kertas Tjiwi Kimia 1.494 Indofood Sukses Makmur 4.211 Astra International 12.549 Bank Negara Indonesia 3.335 return portofolio 0.140997 risiko portofolio 0.099101 excess return beta portofolio 0.881142 Berdasarkan hasil diatas disimpulkan metode indeks tunggal portofolio benar-benar optimal diperoleh perhitungan aktiva bebas risiko Kata Kunci Model Indeks Tunggal portofolio optimal expected return excess return beta cut-off-point'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['abstrak_cleaned'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345bc0fd",
   "metadata": {},
   "source": [
    "## Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2df7d",
   "metadata": {},
   "source": [
    "<p>Data di atas adalah data yang sudah diproses menggunakan TF-IDF untuk menentukan Term Frequency tiap topik. TF-IDF (Term Frequency - Inverse Document Frequency) adalah algoritma praktis yang menggunakan frekuensi kata untuk menentukan seberapa relevan kata-kata itu dengan dokumen tertentu. Ini adalah pendekatan yang relatif sederhana namun intuitif untuk pembobotan kata, memungkinkannya bertindak sebagai titik awal yang bagus untuk berbagai tugas.</p>\n",
    "<h3>Rumus TF-IDF</h3>\n",
    "\n",
    "$$\n",
    "\\operatorname{tf}(t, d)=\\frac{f_{t, d}}{\\sum_{t^{\\prime} \\in d} f_{t^{\\prime}, d}}\n",
    "$$\n",
    "\n",
    "<p></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5163d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect =TfidfVectorizer(stop_words=stop_words,max_features=1000) # to play with. min_df,max_df,max_features etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4886e1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vect_text=vect.fit_transform(df['abstrak_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed3e0ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 421)\n",
      "         0         1         2         3         4         5         6    \\\n",
      "0   0.000000  0.000000  0.000000  0.000000  0.048936  0.146808  0.084054   \n",
      "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4   0.039358  0.000000  0.000000  0.000000  0.000000  0.000000  0.033801   \n",
      "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "6   0.000000  0.049824  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "9   0.000000  0.000000  0.067483  0.067483  0.000000  0.000000  0.000000   \n",
      "10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "11  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "         7         8         9    ...       411       412       413       414  \\\n",
      "0   0.048936  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "1   0.000000  0.000000  0.000000  ...  0.114234  0.000000  0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.117968  ...  0.111643  0.000000  0.000000  0.000000   \n",
      "3   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.079477  0.000000   \n",
      "4   0.000000  0.000000  0.000000  ...  0.031989  0.000000  0.000000  0.033801   \n",
      "5   0.000000  0.000000  0.000000  ...  0.272995  0.000000  0.000000  0.000000   \n",
      "6   0.000000  0.049824  0.042789  ...  0.121485  0.000000  0.000000  0.000000   \n",
      "7   0.000000  0.000000  0.000000  ...  0.289423  0.000000  0.000000  0.000000   \n",
      "8   0.000000  0.000000  0.000000  ...  0.090420  0.000000  0.000000  0.063695   \n",
      "9   0.000000  0.000000  0.000000  ...  0.082272  0.000000  0.000000  0.000000   \n",
      "10  0.000000  0.000000  0.000000  ...  0.102332  0.062953  0.000000  0.000000   \n",
      "11  0.000000  0.000000  0.000000  ...  0.124127  0.000000  0.000000  0.000000   \n",
      "\n",
      "         415       416       417       418       419       420  \n",
      "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3   0.079477  0.068255  0.000000  0.000000  0.000000  0.000000  \n",
      "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "6   0.000000  0.000000  0.049824  0.000000  0.049824  0.000000  \n",
      "7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "10  0.000000  0.000000  0.000000  0.062953  0.000000  0.251811  \n",
      "11  0.000000  0.052463  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[12 rows x 421 columns]\n"
     ]
    }
   ],
   "source": [
    "print(vect_text.shape)\n",
    "#print(vect_text)\n",
    "type(vect_text)\n",
    "df=pd.DataFrame(vect_text.toarray())\n",
    "print(df)\n",
    "idf=vect.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eabcf312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penelitian yamaha\n",
      "1.9555114450274362\n",
      "2.8718021769015913\n"
     ]
    }
   ],
   "source": [
    "dd=dict(zip(vect.get_feature_names(), idf))\n",
    "l=sorted(dd, key=(dd).get)\n",
    "# print(l)\n",
    "print(l[0],l[-1])\n",
    "print(dd['indonesia'])\n",
    "print(dd['strategi'])  # police is most common and forecast is least common among the news headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1974931",
   "metadata": {},
   "source": [
    "## Proses LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123506c4",
   "metadata": {},
   "source": [
    "<p>LSA  adalah metode yang memungkinkan kita mengekstrak topik dari dokumen dengan mengubah teksnya menjadi matriks topik-kata dan topik-dokumen. Prosedur untuk LSA relatif mudah: Ubah korpus teks menjadi matriks istilah dokumen. Menerapkan dekomposisi nilai singular terpotong.</p>\n",
    "\n",
    "$A_{m n}=U_{m m} x S_{m n} x V_{n n}^{T}$\n",
    "\n",
    "<p>Matriks U = baris merepresentasikan vektor pada topic dokumen</p>\n",
    "<p>Matriks V = Garis ini merepresentasikan vektor istilah yang dinyatakan pada topik</p>\n",
    "<p>Matriks S = Matriks diagonal yang memiliki elemen-elemen diagonal yang digunakan sebagai nilai singular A</p>\n",
    "\n",
    "<p>tiap baris pada matriks U merupakan representasi vektor yang terdapat pada dokumen yang sesuai, untuk melakukannya dapat menggunakan library Sklearn yang bernama TruncatedSVD untuk menimplementasikan LSA</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb3b78a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09690831  0.18146421 -0.02851514  0.1024111   0.9549794  -0.04155126\n",
      "   0.00484576 -0.16224744  0.00884487  0.01642086]\n",
      " [ 0.63872184 -0.27881738 -0.21721174  0.29583331 -0.01111476  0.10472484\n",
      "   0.14623667  0.04705709 -0.0447434  -0.42845605]\n",
      " [ 0.38832496  0.73309537 -0.18854167  0.02645431 -0.04388628  0.03203587\n",
      "  -0.01001     0.02308251 -0.01338725  0.01376602]\n",
      " [ 0.15782256  0.01698492  0.38020881  0.58159638 -0.1101049   0.20176257\n",
      "  -0.55983657 -0.34871429 -0.04007405  0.02941382]\n",
      " [ 0.1790468   0.01149926  0.40395146 -0.30668276  0.11333523  0.76857085\n",
      "   0.09314803  0.22635711 -0.21486584 -0.02211677]\n",
      " [ 0.75737264 -0.24648877 -0.13931266 -0.0109003   0.00418276 -0.0340293\n",
      "   0.03637193 -0.00279399  0.04400535 -0.23551116]\n",
      " [ 0.24301604  0.08363384  0.51008217  0.14059333  0.08490396 -0.40141539\n",
      "  -0.13475425  0.67767583  0.0781316  -0.0397776 ]\n",
      " [ 0.40155124 -0.02106521  0.14180716 -0.52571233 -0.01539321 -0.35932148\n",
      "  -0.29783562 -0.25217143 -0.49416622 -0.05622672]\n",
      " [ 0.36579425  0.73682241 -0.13390005 -0.00177682 -0.19022074  0.06783565\n",
      "   0.00738344  0.02619952  0.03845591  0.02740518]\n",
      " [ 0.19850346  0.10127112  0.54666112  0.13009156 -0.09953605 -0.18894068\n",
      "   0.6697523  -0.37150594 -0.00384166  0.04322523]\n",
      " [ 0.52552776 -0.15608898  0.13000315 -0.38792225  0.00356901  0.05236114\n",
      "  -0.16678486 -0.16662324  0.6483258   0.17285426]\n",
      " [ 0.56459104 -0.28639866 -0.21406465  0.20873306 -0.00261217  0.01421725\n",
      "   0.10359297  0.14457571 -0.23058199  0.65040793]]\n",
      "(12, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=10, random_state=42)\n",
    "\n",
    "lsa_top=lsa_model.fit_transform(vect_text)\n",
    "print(lsa_top)\n",
    "print(lsa_top.shape)  # (no_of_doc*no_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1e34d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 :\n",
      "Topic  0  :  9.690830918089622\n",
      "Topic  1  :  18.146420878324257\n",
      "Topic  2  :  -2.8515144537771877\n",
      "Topic  3  :  10.241109589544898\n",
      "Topic  4  :  95.49794017878095\n",
      "Topic  5  :  -4.155125942284578\n",
      "Topic  6  :  0.48457642550380037\n",
      "Topic  7  :  -16.2247435258627\n",
      "Topic  8  :  0.8844870689898237\n",
      "Topic  9  :  1.6420860115021991\n"
     ]
    }
   ],
   "source": [
    "l=lsa_top[0]\n",
    "print(\"Document 0 :\")\n",
    "for i,topic in enumerate(l):\n",
    "  print(\"Topic \",i,\" : \",topic*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "507a4e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 421)\n",
      "[[ 0.00322193  0.00553587  0.00612459 ...  0.01512606  0.00553587\n",
      "   0.06050426]\n",
      " [ 0.00032885  0.00302773  0.00496568 ... -0.0071398   0.00302773\n",
      "  -0.0285592 ]\n",
      " [ 0.01485215  0.02374115  0.0344618  ...  0.0076453   0.02374115\n",
      "   0.03058121]\n",
      " ...\n",
      " [ 0.00976734  0.03701736 -0.02748574 ... -0.01150001  0.03701736\n",
      "  -0.04600004]\n",
      " [-0.01088015  0.00500836 -0.00033354 ...  0.05250993  0.00500836\n",
      "   0.21003973]\n",
      " [-0.00124154 -0.0028267   0.00416041 ...  0.01552029 -0.0028267\n",
      "   0.06208114]]\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape) # (no_of_topics*no_of_words)\n",
    "print(lsa_model.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3b06c",
   "metadata": {},
   "source": [
    "<h3>Hasil TruncatedSVD</h3>\n",
    "\n",
    "berikut adalah contoh 10 kata penting ditiap topik yang diproses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe7bba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "variabel produk pembelian kualitas keputusan penelitian harga bangkalan berpengaruh ratio \n",
      "\n",
      "Topic 1: \n",
      "ratio current equity profitabilitas perusahaan return debt firm leverage risk \n",
      "\n",
      "Topic 2: \n",
      "kompensasi kompetensi kinerja finansial langsung dosen bersaing inovasi keunggulan karyawan \n",
      "\n",
      "Topic 3: \n",
      "bersaing inovasi keunggulan pemasaran pembelian kinerja lamongan optik reza keputusan \n",
      "\n",
      "Topic 4: \n",
      "portofolio saham return optimal risiko astra excess kandidat 12 beta \n",
      "\n",
      "Topic 5: \n",
      "kerja produktivitas faktor pelatihan pegawai pengembangan dinas kelautan perikanan bangkalan \n",
      "\n",
      "Topic 6: \n",
      "kompensasi finansial langsung karyawan nonfinansial pembelian fhitung keputusan signifikan bangkalan \n",
      "\n",
      "Topic 7: \n",
      "kompetensi dosen pedagogik sosial kepribadian madura profesional trunojoyo universitas kerja \n",
      "\n",
      "Topic 8: \n",
      "pelanggan jupiter kota motor sepeda yamaha harga emosional kemudahan persepsi \n",
      "\n",
      "Topic 9: \n",
      "merek cair indomilk susu perilaku psikologis konsumen kebudayaan pribadi sosial \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vect.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36118212",
   "metadata": {},
   "source": [
    "## LDA (Latent Dirichlet Allocation)\n",
    "Latent Dirichlet Allocation (LDA) adalah teknik pemodelan topik yang populer untuk mengekstrak topik dari korpus tertentu. Istilah laten menyampaikan sesuatu yang sudah ada tetapi belum berkembang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6479f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_model=LatentDirichletAllocation(n_components=10,learning_method='online',random_state=42,max_iter=1) \n",
    "# n_components is the number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "162b0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_top=lda_model.fit_transform(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0eb9bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 10)\n",
      "[[0.01263147 0.01263044 0.88632562 0.01263035 0.01263032 0.01263027\n",
      "  0.01263037 0.01263023 0.01263047 0.01263046]\n",
      " [0.01697567 0.01697584 0.01697573 0.01697528 0.0169761  0.0169755\n",
      "  0.01697588 0.0169755  0.84721891 0.01697559]\n",
      " [0.01479292 0.01479315 0.01479308 0.01479292 0.01479307 0.01479294\n",
      "  0.86686174 0.01479427 0.01479292 0.01479298]\n",
      " [0.01526507 0.01526499 0.01526482 0.01526482 0.01526472 0.01526488\n",
      "  0.01526473 0.01526489 0.01526484 0.86261624]\n",
      " [0.01218061 0.89037395 0.01218058 0.01218061 0.01218056 0.01218121\n",
      "  0.01218068 0.01218073 0.01218058 0.01218048]\n",
      " [0.01512833 0.01512837 0.0151284  0.01512821 0.01512852 0.01512813\n",
      "  0.86384415 0.01512826 0.01512848 0.01512916]\n",
      " [0.0160644  0.85541869 0.01606466 0.01606473 0.01606464 0.01606488\n",
      "  0.01606463 0.01606449 0.01606438 0.01606448]\n",
      " [0.01543145 0.0154312  0.01543125 0.01543134 0.01543142 0.86111753\n",
      "  0.01543206 0.01543126 0.01543129 0.01543122]\n",
      " [0.01572078 0.01572104 0.01572088 0.01572093 0.85851185 0.01572074\n",
      "  0.01572116 0.01572093 0.0157209  0.01572079]\n",
      " [0.02074546 0.81329049 0.02074581 0.0207452  0.02074533 0.02074557\n",
      "  0.02074535 0.02074596 0.02074516 0.02074567]\n",
      " [0.01414244 0.0141411  0.0141411  0.01414119 0.01414113 0.01414126\n",
      "  0.87272776 0.01414134 0.01414127 0.0141414 ]\n",
      " [0.01531107 0.01531088 0.01531091 0.01531112 0.01531259 0.01531097\n",
      "  0.01531101 0.01531094 0.86219897 0.01531154]]\n"
     ]
    }
   ],
   "source": [
    "print(lda_top.shape)  # (no_of_doc,no_of_topics)\n",
    "print(lda_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84e59ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "for i in lda_top[0]:\n",
    "  sum=sum+i\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64e8423a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: \n",
      "Topic  0 :  1.263146557345191 %\n",
      "Topic  1 :  1.2630437603801457 %\n",
      "Topic  2 :  88.6325622543892 %\n",
      "Topic  3 :  1.2630351342744983 %\n",
      "Topic  4 :  1.2630321370350317 %\n",
      "Topic  5 :  1.263026713497747 %\n",
      "Topic  6 :  1.263036893867184 %\n",
      "Topic  7 :  1.2630226282692552 %\n",
      "Topic  8 :  1.2630474309960575 %\n",
      "Topic  9 :  1.2630464899456904 %\n"
     ]
    }
   ],
   "source": [
    "# composition of doc 0 for eg\n",
    "print(\"Document 0: \")\n",
    "for i,topic in enumerate(lda_top[0]):\n",
    "  print(\"Topic \",i,\": \",topic*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd92c9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87031051 0.81812977 0.8104402  ... 0.86630556 0.69821862 0.89025664]\n",
      " [0.82180301 0.79556085 0.78032951 ... 0.73390106 0.82174958 0.76218601]\n",
      " [0.97260115 0.86177628 0.93040481 ... 0.89124693 0.81467856 0.77771142]\n",
      " ...\n",
      " [0.78882914 0.98303555 0.83039772 ... 0.83957116 0.85705763 0.7821602 ]\n",
      " [0.88628133 0.66669771 0.97110011 ... 0.80922445 0.73848641 0.95393085]\n",
      " [0.80594826 0.95143676 0.85264752 ... 0.84527538 0.81113257 0.85353812]]\n",
      "(10, 421)\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.components_)\n",
    "print(lda_model.components_.shape)  # (no_of_topics*no_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef85dd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "fenomenologi sukses bertujuan fleksibilitas return metode manakah manusia indomilk klasik \n",
      "\n",
      "Topic 1: \n",
      "produktivitas langsung pelatihan versi kompensasi debt memakai finansial tercapai kompetensi \n",
      "\n",
      "Topic 2: \n",
      "diperoleh 377 kandidat serviscape model 417 wawancara terbukti bimbingan mt \n",
      "\n",
      "Topic 3: \n",
      "skala instansi koefisiensi kelautan ftabel kepuasan hasil 2008 pedagogik pasien \n",
      "\n",
      "Topic 4: \n",
      "universitas positivisme tercapai upaya responden dominan moch membentuk manakah liquid \n",
      "\n",
      "Topic 5: \n",
      "reputasi pengaruh serviscape 2011 expected fleksibilitas garam pelanggan partisipasi diolah \n",
      "\n",
      "Topic 6: \n",
      "pengujian masuk kecamatan perusahaan primer pengembangan ftabel rm surabaya bangkalan \n",
      "\n",
      "Topic 7: \n",
      "05 multi random kepuasan wawancara probality 494 produktivitas kuesioner 000 \n",
      "\n",
      "Topic 8: \n",
      "likuiditas aktiva international pengembangan komposisi fhitung reliabilitas 973 540 teknik \n",
      "\n",
      "Topic 9: \n",
      "dibentuk lestari firm penjualan bimbingan besarnya reputasi conclusion indomilk 549 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vect.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lda_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
